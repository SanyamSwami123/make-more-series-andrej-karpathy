{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM1XoTQJ9rlwh1gAY/RMUcC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SanyamSwami123/make-more-series-andrej-karpathy/blob/main/2_bigram_language_model_optimised_code.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Bigram: one character predicts the next one with a lookup table of counts"
      ],
      "metadata": {
        "id": "sIIcohvnJIJc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import torch.nn.functional as F"
      ],
      "metadata": {
        "id": "JVdwUw23p5GI"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "words = open('names.txt', 'r').read().splitlines()"
      ],
      "metadata": {
        "id": "JuoPurF8p9nR"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "N = torch.zeros((27,27), dtype= torch.int32) # we have 26 unique character and 2 special character <S> and <E>, so row=28, col =28"
      ],
      "metadata": {
        "id": "2jC6-bT6qNEp"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chars = sorted(list(set(''.join(words))))\n",
        "stoi = {s:i+1 for i ,s in enumerate(chars)}\n",
        "stoi['.'] = 0\n",
        "itos = {i:s for s,i in stoi.items()}"
      ],
      "metadata": {
        "id": "udLNHobsqPrm"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sFTfDMGHpnuw",
        "outputId": "ae907ecc-d80d-44b0-9072-7cfeca8bba60"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ". e\n",
            "e m\n",
            "m m\n",
            "m a\n",
            "a .\n"
          ]
        }
      ],
      "source": [
        "# creating the training set of biagram (xs (inputs), ys (ouput/labels))\n",
        "xs, ys= [], []\n",
        "for w  in words[:1]:\n",
        "  chs = ['.'] + list(w)+['.']\n",
        "  for ch1, ch2 in zip(chs,  chs[1:]):\n",
        "    ix1 = stoi[ch1]\n",
        "    ix2 = stoi[ch2]\n",
        "    print(ch1, ch2)\n",
        "    xs.append(ix1)\n",
        "    ys.append(ix2)\n",
        "\n",
        "xs = torch.tensor(xs)\n",
        "ys = torch.tensor(ys)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "xs, ys"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5DyN8-KeqEYA",
        "outputId": "67fa7c9a-8995-475a-fa2a-4d500c26e02a"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([ 0,  5, 13, 13,  1]), tensor([ 5, 13, 13,  1,  0]))"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# neural network approach\n",
        "x_enc = F.one_hot(xs, num_classes=27).float()"
      ],
      "metadata": {
        "id": "ovmNSwm7qTXf"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(x_enc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 169
        },
        "id": "aZQ4_koWtxbJ",
        "outputId": "b6db6dc1-8c82-4263-c6ae-4a9f38d34440"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7a5095214640>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_enc.dtype"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "quovwleTuDdL",
        "outputId": "88e246ed-8a2e-4374-8bd1-fc7653e2df1c"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.float32"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "w = torch.randn((27,27)) # matrix multiplication (5, 27) @ (27, 27) --> (5,27)"
      ],
      "metadata": {
        "id": "om0YL3TQul8p"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "logits = (x_enc @  w) # log counts\n",
        "counts = logits.exp() # equivalent to the N matrix #exp in math see the graph (converting the negative number towards positive but it will never be below zero and positives to more positive).\n",
        "prob = counts /counts.sum(1, keepdims = True) # probabilities for next character\n",
        "prob #all value sum =1"
      ],
      "metadata": {
        "id": "qrK_lWuhx6pa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0225408d-64ff-4730-d2b7-825b7c969e86"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.0063, 0.0073, 0.0039, 0.0219, 0.0056, 0.0029, 0.0250, 0.0092, 0.4952,\n",
              "         0.0031, 0.0180, 0.0448, 0.0638, 0.0025, 0.0207, 0.0187, 0.0093, 0.0172,\n",
              "         0.0190, 0.0067, 0.0096, 0.0143, 0.0103, 0.0186, 0.0950, 0.0413, 0.0100],\n",
              "        [0.0059, 0.0106, 0.1204, 0.0769, 0.0014, 0.0113, 0.0193, 0.0472, 0.0056,\n",
              "         0.0677, 0.0301, 0.0032, 0.0110, 0.0244, 0.0484, 0.0130, 0.0066, 0.0254,\n",
              "         0.1847, 0.0299, 0.0910, 0.0142, 0.0219, 0.0065, 0.0127, 0.0400, 0.0706],\n",
              "        [0.0060, 0.0178, 0.0295, 0.0222, 0.0134, 0.0285, 0.0385, 0.1091, 0.0167,\n",
              "         0.0488, 0.0474, 0.0020, 0.0242, 0.1412, 0.0225, 0.0026, 0.0163, 0.0174,\n",
              "         0.0395, 0.0541, 0.0486, 0.0090, 0.0952, 0.0083, 0.0235, 0.0888, 0.0292],\n",
              "        [0.0060, 0.0178, 0.0295, 0.0222, 0.0134, 0.0285, 0.0385, 0.1091, 0.0167,\n",
              "         0.0488, 0.0474, 0.0020, 0.0242, 0.1412, 0.0225, 0.0026, 0.0163, 0.0174,\n",
              "         0.0395, 0.0541, 0.0486, 0.0090, 0.0952, 0.0083, 0.0235, 0.0888, 0.0292],\n",
              "        [0.0098, 0.0406, 0.0455, 0.0093, 0.0379, 0.0215, 0.1220, 0.0903, 0.0600,\n",
              "         0.0187, 0.0454, 0.0133, 0.0051, 0.0604, 0.0320, 0.0169, 0.0293, 0.0157,\n",
              "         0.0237, 0.0300, 0.0698, 0.0118, 0.0813, 0.0121, 0.0668, 0.0163, 0.0147]])"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prob[1].sum() # each row sum is prob 1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6t7_lplG0pIQ",
        "outputId": "d0eb68b6-fb3f-444f-b658-d01a4b0b676a"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(1.)"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prob[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_QdQy8G80uUI",
        "outputId": "0140902f-30dd-4fce-f028-286e6608835b"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.0063, 0.0073, 0.0039, 0.0219, 0.0056, 0.0029, 0.0250, 0.0092, 0.4952,\n",
              "        0.0031, 0.0180, 0.0448, 0.0638, 0.0025, 0.0207, 0.0187, 0.0093, 0.0172,\n",
              "        0.0190, 0.0067, 0.0096, 0.0143, 0.0103, 0.0186, 0.0950, 0.0413, 0.0100])"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# randomly intialize 27 neurons weight, each neuron receives 27 inputs\n",
        "g = torch.Generator().manual_seed(42)\n",
        "w = torch.randn((27,27), generator=g)"
      ],
      "metadata": {
        "id": "oCRpNFYM3E19"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_enc = F.one_hot(xs, num_classes=27).float() # input to the network: one hot encoding\n",
        "logits = x_enc @ w # output pre-softmax, predict log-counts\n",
        "counts = logits.exp() # counts, equivalent to N\n",
        "prob = counts / counts.sum(1, keepdims=True) #probabilities for next character\n",
        "# btw: the last  2lines here are together called softmax (softmax always puts number greater than 0)\n",
        "# our neural network here is:\n",
        "# linear layer\n",
        "#    |\n",
        "#    \\/\n",
        "# softmax layer"
      ],
      "metadata": {
        "id": "68mNNNK539cW"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nlls = torch.zeros(5) # negative log likelihood note: nll directly proportional to the loss.\n",
        "for i in range(5):\n",
        "  # i-th bigram:\n",
        "  x = xs[i].item() # input character index\n",
        "  y = ys[i].item() # label character index\n",
        "  print('--------')\n",
        "  print(f'bigram example {i+1}: {itos[x]} {itos[y]} (indexes {x}, {y})')\n",
        "  print('input to the neural net:', x)\n",
        "  print('output probabilities from the neural net:', prob[i])\n",
        "  print('label (actual next character):', y)\n",
        "  p = prob[i, y]\n",
        "  print('probability assigned by the net to the the correct character:', p.item())\n",
        "  logp = torch.log(p)\n",
        "  print('log likelihood:', logp.item())\n",
        "  nll = -logp\n",
        "  print('negative log likelihood:', nll.item())\n",
        "  nlls[i] = nll\n",
        "\n",
        "print('=========')\n",
        "print('average negative log likelihood, i.e. loss =', nlls.mean().item())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wBh71ofy5QGY",
        "outputId": "be584b74-ddfa-4970-ab3d-75ff9a9a4971"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------\n",
            "bigram example 1: . e (indexes 0, 5)\n",
            "input to the neural net: 0\n",
            "output probabilities from the neural net: tensor([0.1230, 0.0793, 0.0441, 0.0022, 0.0353, 0.0052, 0.0172, 0.0036, 0.0084,\n",
            "        0.0932, 0.0121, 0.0044, 0.0087, 0.0102, 0.0083, 0.0384, 0.0926, 0.0153,\n",
            "        0.0109, 0.0278, 0.0084, 0.0527, 0.0399, 0.0962, 0.0644, 0.0655, 0.0330])\n",
            "label (actual next character): 5\n",
            "probability assigned by the net to the the correct character: 0.005211981479078531\n",
            "log likelihood: -5.256795406341553\n",
            "negative log likelihood: 5.256795406341553\n",
            "--------\n",
            "bigram example 2: e m (indexes 5, 13)\n",
            "input to the neural net: 5\n",
            "output probabilities from the neural net: tensor([0.0396, 0.0698, 0.0227, 0.0037, 0.0562, 0.0153, 0.0626, 0.0112, 0.0421,\n",
            "        0.0084, 0.0581, 0.1125, 0.0951, 0.0292, 0.0181, 0.0107, 0.0247, 0.0316,\n",
            "        0.0586, 0.0140, 0.1109, 0.0019, 0.0147, 0.0067, 0.0502, 0.0033, 0.0280])\n",
            "label (actual next character): 13\n",
            "probability assigned by the net to the the correct character: 0.029176028445363045\n",
            "log likelihood: -3.5344078540802\n",
            "negative log likelihood: 3.5344078540802\n",
            "--------\n",
            "bigram example 3: m m (indexes 13, 13)\n",
            "input to the neural net: 13\n",
            "output probabilities from the neural net: tensor([0.0123, 0.0078, 0.0250, 0.0187, 0.0050, 0.0125, 0.0074, 0.0099, 0.1254,\n",
            "        0.1147, 0.0934, 0.0176, 0.0144, 0.0029, 0.0085, 0.0116, 0.1132, 0.0138,\n",
            "        0.0203, 0.1464, 0.0943, 0.0242, 0.0326, 0.0140, 0.0340, 0.0149, 0.0053])\n",
            "label (actual next character): 13\n",
            "probability assigned by the net to the the correct character: 0.002911691088229418\n",
            "log likelihood: -5.8390212059021\n",
            "negative log likelihood: 5.8390212059021\n",
            "--------\n",
            "bigram example 4: m a (indexes 13, 1)\n",
            "input to the neural net: 13\n",
            "output probabilities from the neural net: tensor([0.0123, 0.0078, 0.0250, 0.0187, 0.0050, 0.0125, 0.0074, 0.0099, 0.1254,\n",
            "        0.1147, 0.0934, 0.0176, 0.0144, 0.0029, 0.0085, 0.0116, 0.1132, 0.0138,\n",
            "        0.0203, 0.1464, 0.0943, 0.0242, 0.0326, 0.0140, 0.0340, 0.0149, 0.0053])\n",
            "label (actual next character): 1\n",
            "probability assigned by the net to the the correct character: 0.007754605263471603\n",
            "log likelihood: -4.859468460083008\n",
            "negative log likelihood: 4.859468460083008\n",
            "--------\n",
            "bigram example 5: a . (indexes 1, 0)\n",
            "input to the neural net: 1\n",
            "output probabilities from the neural net: tensor([0.0934, 0.0195, 0.0256, 0.0191, 0.0581, 0.0062, 0.0103, 0.0197, 0.1369,\n",
            "        0.0338, 0.0161, 0.0334, 0.0113, 0.0052, 0.0665, 0.0102, 0.0135, 0.0069,\n",
            "        0.2054, 0.0072, 0.0151, 0.0099, 0.0127, 0.0266, 0.0416, 0.0151, 0.0809])\n",
            "label (actual next character): 0\n",
            "probability assigned by the net to the the correct character: 0.09339158236980438\n",
            "log likelihood: -2.3709540367126465\n",
            "negative log likelihood: 2.3709540367126465\n",
            "=========\n",
            "average negative log likelihood, i.e. loss = 4.372129440307617\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# optimised code"
      ],
      "metadata": {
        "id": "8xlr_ffTL7lQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import torch.nn.functional as F"
      ],
      "metadata": {
        "id": "eINWeHAXMFRe"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "words = open('names.txt', 'r').read().splitlines()"
      ],
      "metadata": {
        "id": "W59M0KbaMF9M"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "N = torch.zeros((27,27), dtype= torch.int32) # we have 26 unique character and 2 special character <S> and <E>, so row=28, col =28"
      ],
      "metadata": {
        "id": "yxJ5DpuKMPOM"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chars = sorted(list(set(''.join(words))))\n",
        "stoi = {s:i+1 for i ,s in enumerate(chars)}\n",
        "stoi['.'] = 0\n",
        "itos = {i:s for s,i in stoi.items()}"
      ],
      "metadata": {
        "id": "iE9a8WovMPHr"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create the dataset (xs (inputs), ys (ouput/labels))\n",
        "xs, ys= [], []\n",
        "for w  in words:\n",
        "  chs = ['.'] + list(w)+['.']\n",
        "  for ch1, ch2 in zip(chs,  chs[1:]):\n",
        "    ix1 = stoi[ch1]\n",
        "    ix2 = stoi[ch2]\n",
        "    xs.append(ix1)\n",
        "    ys.append(ix2)\n",
        "xs = torch.tensor(xs)\n",
        "ys = torch.tensor(ys)\n",
        "num = xs.nelement()\n",
        "print('number of examples: ', num)\n",
        "\n",
        "# initialize the 'network'\n",
        "# randomly intialize 27 neurons weight, each neuron receives 27 inputs\n",
        "g = torch.Generator().manual_seed(42)\n",
        "w = torch.randn((27,27), generator=g, requires_grad=True) # requires the grad to be true so that the gradient can be calculated and can be tracked"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dd5hv4-8-suC",
        "outputId": "61f82e8c-e8c7-4cce-b050-bc54ce82bc42"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "number of examples:  228146\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# gradient decent/ training\n",
        "for k in range(100): # 100 iterations (epochs)\n",
        "\n",
        "  ## forward pass\n",
        "  x_enc = F.one_hot(xs, num_classes=27).float() # input to the network: one hot encoding\n",
        "  logits = x_enc @ w # output pre-softmax, predict log-counts\n",
        "  counts = logits.exp() # counts, equivalent to N\n",
        "  prob = counts / counts.sum(1, keepdims=True)\n",
        "  loss = -prob[torch.arange(num), ys].log().mean() + 0.01 *(w**2).mean() # (average negative log likelihood + regularizationie) i.e. loss\n",
        "  print(loss.item())\n",
        "\n",
        "  ## backward pass\n",
        "  w.grad = None # set to zero the gradient\n",
        "  loss.backward()\n",
        "\n",
        "#update/step parameters/weights\n",
        "# for p in w.parameters():\n",
        "  w.data += -50 * w.grad # 0.1 is learning_rate"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UCR7LXpu6bCl",
        "outputId": "40f0b997-f28d-4fb4-a65e-838ae63a5398"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3.706477165222168\n",
            "3.373866081237793\n",
            "3.1580393314361572\n",
            "3.015209197998047\n",
            "2.9186456203460693\n",
            "2.847991466522217\n",
            "2.7949209213256836\n",
            "2.754241466522217\n",
            "2.722402334213257\n",
            "2.6969125270843506\n",
            "2.6760470867156982\n",
            "2.6586241722106934\n",
            "2.643829345703125\n",
            "2.6310932636260986\n",
            "2.6200039386749268\n",
            "2.610258102416992\n",
            "2.6016242504119873\n",
            "2.593924045562744\n",
            "2.58701491355896\n",
            "2.580784320831299\n",
            "2.575138568878174\n",
            "2.5700018405914307\n",
            "2.565310478210449\n",
            "2.5610110759735107\n",
            "2.557058334350586\n",
            "2.5534133911132812\n",
            "2.5500428676605225\n",
            "2.546917676925659\n",
            "2.5440127849578857\n",
            "2.541306734085083\n",
            "2.5387794971466064\n",
            "2.536414861679077\n",
            "2.534198045730591\n",
            "2.5321154594421387\n",
            "2.530156373977661\n",
            "2.5283100605010986\n",
            "2.5265681743621826\n",
            "2.524921417236328\n",
            "2.5233635902404785\n",
            "2.521888017654419\n",
            "2.5204882621765137\n",
            "2.5191593170166016\n",
            "2.5178964138031006\n",
            "2.516695499420166\n",
            "2.515552043914795\n",
            "2.514462947845459\n",
            "2.5134246349334717\n",
            "2.5124330520629883\n",
            "2.511486768722534\n",
            "2.510582208633423\n",
            "2.5097174644470215\n",
            "2.508889675140381\n",
            "2.5080971717834473\n",
            "2.507338285446167\n",
            "2.506610631942749\n",
            "2.5059125423431396\n",
            "2.505242109298706\n",
            "2.50459885597229\n",
            "2.5039801597595215\n",
            "2.5033857822418213\n",
            "2.5028135776519775\n",
            "2.502262830734253\n",
            "2.501732587814331\n",
            "2.5012216567993164\n",
            "2.5007288455963135\n",
            "2.500253915786743\n",
            "2.4997951984405518\n",
            "2.499352216720581\n",
            "2.498924493789673\n",
            "2.4985108375549316\n",
            "2.498110771179199\n",
            "2.497724771499634\n",
            "2.497349977493286\n",
            "2.49698805809021\n",
            "2.4966373443603516\n",
            "2.4962968826293945\n",
            "2.4959676265716553\n",
            "2.49564790725708\n",
            "2.495337724685669\n",
            "2.495037078857422\n",
            "2.4947450160980225\n",
            "2.4944615364074707\n",
            "2.4941859245300293\n",
            "2.4939184188842773\n",
            "2.4936585426330566\n",
            "2.493405342102051\n",
            "2.493159294128418\n",
            "2.492920160293579\n",
            "2.492687463760376\n",
            "2.4924612045288086\n",
            "2.4922401905059814\n",
            "2.492025375366211\n",
            "2.4918160438537598\n",
            "2.491611957550049\n",
            "2.4914138317108154\n",
            "2.4912197589874268\n",
            "2.4910311698913574\n",
            "2.490847110748291\n",
            "2.4906675815582275\n",
            "2.490492343902588\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# finally simple from the 'neural network' model\n",
        "g = torch.Generator().manual_seed(42)\n",
        "\n",
        "for i in range(5):\n",
        "  out = []\n",
        "  ix = 0\n",
        "  while True:\n",
        "    # -------\n",
        "    # now:\n",
        "    x_enc = F.one_hot(torch.tensor([ix]), num_classes=27).float()\n",
        "    logits = x_enc @ w # predict log-counts\n",
        "    counts = logits.exp() # counts, equivalent to N\n",
        "    p = counts / counts.sum(1, keepdims=True) # probabilities for next character\n",
        "    # ----------\n",
        "\n",
        "    ix = torch.multinomial(p, num_samples=1, replacement=True, generator=g).item()\n",
        "    out.append(itos[ix])\n",
        "    if ix == 0:\n",
        "      break\n",
        "  print(out)\n",
        "  print(''.join(out))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eXZlQPHK9U3r",
        "outputId": "33c92f45-0f32-47ac-9264-ef7323f9edd8"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['y', 'a', '.']\n",
            "ya.\n",
            "['s', 'y', 'a', 'h', 'a', 'v', 'i', 'l', 'i', 'n', '.']\n",
            "syahavilin.\n",
            "['d', 'l', 'e', 'e', 'k', 'a', 'h', 'm', 'a', 'n', 'g', 'o', 'n', 'y', 'a', '.']\n",
            "dleekahmangonya.\n",
            "['t', 'r', 'y', 'a', 'h', 'e', '.']\n",
            "tryahe.\n",
            "['c', 'h', 'e', 'n', '.']\n",
            "chen.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# conclusion: we have covered bigram character level language model."
      ],
      "metadata": {
        "id": "LH7whELNLw3R"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bY3xLJI4Hmhc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}