{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNyR86E8bURLkO3aqesXeDi",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SanyamSwami123/make-more-series-andrej-karpathy/blob/main/ExtractText_FromPDF_Using_Langchain.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Explanation:** Langchain is a powerful framework designed to facilitate the development of application that integrate with LLM and other language-related-topics. It provides abstraction and utilities for building complex workflows involving text generation, document analysis, and more.\n",
        "\n",
        "**In-Short**: Langchain is a framework for integrating and managing LLMs within various workflows and application."
      ],
      "metadata": {
        "id": "4FLrX1zpkfhS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-MTZQmLTkRJL",
        "outputId": "ceab16ea-3dd5-441e-bd49-77a9c2740c4d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.10/dist-packages (0.3.0)\n",
            "Requirement already satisfied: pdfplumber in /usr/local/lib/python3.10/dist-packages (0.11.4)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.44.2)\n",
            "Collecting langchain_huggingface\n",
            "  Downloading langchain_huggingface-0.1.0-py3-none-any.whl.metadata (1.3 kB)\n",
            "Requirement already satisfied: langchain-community in /usr/local/lib/python3.10/dist-packages (0.3.0)\n",
            "Requirement already satisfied: faiss-cpu in /usr/local/lib/python3.10/dist-packages (1.8.0.post1)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.34)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.10.5)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Requirement already satisfied: langchain-core<0.4.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.3.0)\n",
            "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.3.0)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.1.121)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.26.4)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.9.1)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.32.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.5.0)\n",
            "Requirement already satisfied: pdfminer.six==20231228 in /usr/local/lib/python3.10/dist-packages (from pdfplumber) (20231228)\n",
            "Requirement already satisfied: Pillow>=9.1 in /usr/local/lib/python3.10/dist-packages (from pdfplumber) (9.4.0)\n",
            "Requirement already satisfied: pypdfium2>=4.18.0 in /usr/local/lib/python3.10/dist-packages (from pdfplumber) (4.30.0)\n",
            "Requirement already satisfied: charset-normalizer>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from pdfminer.six==20231228->pdfplumber) (3.3.2)\n",
            "Requirement already satisfied: cryptography>=36.0.0 in /usr/local/lib/python3.10/dist-packages (from pdfminer.six==20231228->pdfplumber) (43.0.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.24.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.5.15)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.5)\n",
            "Collecting sentence-transformers>=2.6.0 (from langchain_huggingface)\n",
            "  Downloading sentence_transformers-3.1.0-py3-none-any.whl.metadata (23 kB)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (0.6.7)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (2.5.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.11.1)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.22.0)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.6.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.0->langchain) (1.33)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain) (0.27.2)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.7)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.3 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.23.3)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community) (1.0.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.8)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2024.8.30)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers>=2.6.0->langchain_huggingface) (2.4.0+cu121)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence-transformers>=2.6.0->langchain_huggingface) (1.3.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers>=2.6.0->langchain_huggingface) (1.13.1)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.0)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.10/dist-packages (from cryptography>=36.0.0->pdfminer.six==20231228->pdfplumber) (1.17.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (3.7.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.0.5)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.0->langchain) (3.0.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain_huggingface) (1.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain_huggingface) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain_huggingface) (3.1.4)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.0.0)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers>=2.6.0->langchain_huggingface) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers>=2.6.0->langchain_huggingface) (3.5.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six==20231228->pdfplumber) (2.22)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.2.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers>=2.6.0->langchain_huggingface) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.11.0->sentence-transformers>=2.6.0->langchain_huggingface) (1.3.0)\n",
            "Downloading langchain_huggingface-0.1.0-py3-none-any.whl (20 kB)\n",
            "Downloading sentence_transformers-3.1.0-py3-none-any.whl (249 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m249.1/249.1 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: sentence-transformers, langchain_huggingface\n",
            "Successfully installed langchain_huggingface-0.1.0 sentence-transformers-3.1.0\n"
          ]
        }
      ],
      "source": [
        "#1. install required packages\n",
        "!pip install langchain pdfplumber transformers langchain_huggingface langchain-community faiss-cpu"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pdfplumber\n",
        "from transformers import pipeline, GPT2Tokenizer, GPT2LMHeadModel\n",
        "from langchain.prompts import PromptTemplate\n",
        "\n",
        "# Extract text from PDF\n",
        "def extract_text_from_pdf(pdf_path):\n",
        "    text = \"\"\n",
        "    with pdfplumber.open(pdf_path) as pdf:\n",
        "        for page in pdf.pages:\n",
        "            text += page.extract_text() or \"\"\n",
        "    return text\n",
        "\n",
        "# Define the prompt template\n",
        "# prompt_template = PromptTemplate(\n",
        "#     input_variables=[\"text\"],\n",
        "#     template=\"\"\"\n",
        "#     Extract the following details from the W-2 form text:\n",
        "\n",
        "#     - Employee's social security number\n",
        "#     - Employer identification number\n",
        "#     - Wages, tips, other compensation\n",
        "#     - Federal income tax withheld\n",
        "#     - Social security wages\n",
        "#     - Social security tax withheld\n",
        "#     - Medicare wages and tips\n",
        "#     - Medicare tax withheld\n",
        "#     - Employee's first name and initial\n",
        "#     - Employee's last name\n",
        "#     - Employer's name, address, and ZIP code\n",
        "\n",
        "\n",
        "\n",
        "#     Output format:\n",
        "#     - Employee's social security number:\n",
        "#     - Employer identification number:\n",
        "#     - Wages, tips, other compensation:\n",
        "#     - Federal income tax withheld:\n",
        "#     - Social security wages:\n",
        "#     - Social security tax withheld:\n",
        "#     - Medicare wages and tips:\n",
        "#     - Medicare tax withheld:\n",
        "#     - Employee's first name and initial:\n",
        "#     - Employee's last name:\n",
        "#     - Employer's name, address, and ZIP code:\n",
        "#     \"\"\"\n",
        "# )\n",
        "\n",
        "prompt_template = PromptTemplate(\n",
        "    input_variables=[\"text\"],\n",
        "    template=\"\"\"\n",
        "    From the following W-2 form text, extract the Employee's first name and initial and last name.\n",
        "\n",
        "    Output format:\n",
        "    - Employee's first name and initial:\n",
        "    - Last name:\n",
        "    \"\"\"\n",
        ")\n",
        "  #  Text:\n",
        "    # {text}\n",
        "\n",
        "   # Text:\n",
        "    # {text}\n",
        "# Initialize the text generation pipeline from Hugging Face\n",
        "model_name = \"gpt2\"  # You can use another model if needed\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
        "model = GPT2LMHeadModel.from_pretrained(model_name)\n",
        "text_generator = pipeline(\"text-generation\", model=model, tokenizer=tokenizer)\n",
        "\n",
        "def generate_text(prompt):\n",
        "    # Tokenize and generate text with proper truncation\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\", truncation=True, max_length=512)\n",
        "    outputs = model.generate(inputs[\"input_ids\"], max_length=1024, num_return_sequences=1, pad_token_id=tokenizer.eos_token_id)\n",
        "    return tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "\n",
        "# Extract information using the model\n",
        "def extract_information_from_text(text):\n",
        "    try:\n",
        "        # Generate text using the model\n",
        "        prompt = prompt_template.format(text=text)\n",
        "        response = generate_text(prompt)\n",
        "        return response\n",
        "    except Exception as e:\n",
        "        print(f\"Error during text generation: {e}\")\n",
        "        return None\n",
        "\n",
        "# Example usage\n",
        "pdf_path = \"/content/W2_XL_input_clean_2999.pdf\"  # Replace with your PDF file path\n",
        "text = extract_text_from_pdf(pdf_path)\n",
        "extracted_info = extract_information_from_text(text)\n",
        "print(extracted_info)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W2sJWo8b4FIr",
        "outputId": "a4a63c69-a2dd-4ccb-d520-9eacde743da9"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "    From the following W-2 form text, extract the Employee's first name and initial and last name.\n",
            "\n",
            "    Output format:\n",
            "    - Employee's first name and initial: \n",
            "    - Last name:\n",
            "     - Company:\n",
            "\n",
            "----------------------------------------------------\n",
            "\n",
            "\n",
            "The following text is from (W-2 format):\n",
            "\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "\n",
            "1.1.1.3 Description\n",
            "\n",
            "------------------------------\n",
            "\n",
            "This is a W-2 Form T-90 which forms the employee's first name and final name. The form is a copy of the Employee's W-1 Form T-90. The type of input is a two-line double quoted list, first and last names and then additional company and company, and final name (using the name of employee).\n",
            "\n",
            "\n",
            "1.1.1.4 Description\n",
            "\n",
            "---------------\n",
            "\n",
            "\n",
            "1.1.1.5 Description\n",
            "\n",
            "---------------\n",
            "\n",
            "\n",
            "1.1.1.6 Description\n",
            "\n",
            "-------------------------------\n",
            "\n",
            "This form forms the employee's last name and first company and company, and final name of the worker with the company for the other companies.\n",
            "\n",
            "\n",
            "1.2. Inactive Employees\n",
            "\n",
            "------------------------\n",
            "\n",
            "This forms the employees' only active role. This forms only the position assigned once, where the position will be filled from the beginning, where the positions cannot be filled, when not occupied, when occupied, or when a decision is made on whether or not to have an active role\n",
            "\n",
            "(all active jobs have names, only jobs that are filled when not in active role):\n",
            "\n",
            "Employees - This is a special part of the job description.\n",
            "\n",
            "Active Positions\n",
            "\n",
            "- This is a special part of the job description. Occupation (including current, past, and current jobs) - This field is blank when no active job is listed.\n",
            "\n",
            "(no active job is listed. If no vacant job is listed, it is blank;\n",
            "\n",
            "the vacant job list is blank. If empty, no vacant position is listed for the position to be filled;\n",
            "\n",
            "the vacancy exists, except for inactive position, and only for non-active job openings as described above;\n",
            "\n",
            "if no vacancy exists, then no active job is active at the position to be filled.\n",
            "\n",
            "- This is a special part of the job description. Occupation (including current, past, and current jobs) - This field is blank when no active job is listed. Occupation (including current, past, and current jobs) is blank if no vacant job is listed, or if vacant positions exist if empty.\n",
            "\n",
            "2. The Filing Times\n",
            "\n",
            "2.1. Terminals\n",
            "\n",
            "- The Filing Times is available through the W-2 form.\n",
            "\n",
            "2.1.2 Terminals\n",
            "\n",
            "2.1.2\n",
            "\n",
            "[Reset: Current]\n",
            "\n",
            "2.1.2.1 Terminals\n",
            "\n",
            "[Reset: This position fills in after 3 or 4 years.]\n",
            "\n",
            "3. Summary\n",
            "\n",
            "\n",
            "3.1. Assignment of Active Positions\n",
            "\n",
            "3.1.1.1\n",
            "\n",
            "[Reset: This role is filled following 3 or 4 years; a vacant position is empty until filled at least 1 year after the last change to it.]\n",
            "\n",
            "3.1.1.2\n",
            "\n",
            "[Reset:\n",
            "\n",
            "This role is not filled, unless all positions in the \"Active Positions\" category are filled. (If the position is filled and occupied at one time or after two years, the new position should be filled or replaced by this, or at least it is filled the first time after.\n",
            "\n",
            "If the job is filled, and any active job is filled, the active position is occupied, and the inactive job is occupied when not in active role.)\n",
            "\n",
            "4. The Job History\n",
            "\n",
            "4.1. Inactive Positions\n",
            "\n",
            "- This job description contains the active role, but may not show the job with which the position was assigned, if the occupation is occupied, and in which it had no active job. If a vacant job is listed and the empty job exists, then no active job is active; if a vacant job is listed, then either vacancy is marked, or this position replaces in the past.\n",
            "\n",
            "4.1.2 Job Titles\n",
            "\n",
            "- This job description contains the job title, the number of posts that the job was assigned, the number of posts that the job was created. The job title is indicated by a line of text under the name of a position, the number of posts that were created, and the number of posts that were created that month. There is no job title. Some vacant and active positions may be filled by an individual who has no knowledge of their occupation. If a vacancy occurs without an active job.\n",
            "\n",
            "4.1.3 Employment and Retention\n",
            "\n",
            "- Some occupations have vacancies which are filled by the employer for a\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## What we are doing:\n",
        "1. **reading a pdf file:**\n",
        "- we have a file that is a book or a form. we need to look inside and read the words.\n",
        "- This part of the code takes the file, opens it, and pulls out all the text.\n",
        "2.  **Preparing the text for the model**:\n",
        "- Imagine we want to ask a robot to find specific information information from the text we just read. We need to give the robot a special question or \"prompt\" that tells it what to look for.\n",
        "- This prompt has placeholder where we put our text.\n",
        "3. **Using a smart robot to answer questions:**\n",
        "- We have a smart robot (a model in our case from **hugging face**) that can read text and answer questions based on it. We use this robot to generate answers from the text.\n"
      ],
      "metadata": {
        "id": "7ZqWEedQd99m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Detailed steps:\n",
        "1. Extracting Text from a PDF file.\n",
        "- `extract_text_from_pdf`, Here we opens the pdf file, reads every page, and collects all the text from those pages.\n",
        "- steps: `open`>`read each page`>`collect and combine te text`\n",
        "2. creating a Prompt Template.\n",
        "- `What it does`, sets up a template that tells the robot exactly what details to look for in the text give it.\n",
        "- `How it works`,\n",
        "  - define template with placeholder where our actual text will go.\n",
        "  - The template outlines what details we want to extract.\n",
        "3. Preparing the robot (model) to answer Questions.\n",
        "- `what it does`,sets up a smart robot that can generate text based on the prompt we give it.\n",
        "- `how it works`,\n",
        "  - Load the robot model and its \"language\" skills.\n",
        "  - Prepare it to read and generate text.\n",
        "4. Generate answers with the robot.\n",
        "- `what it does`, sends the prompt to the robot and gets back an answer.\n",
        "- `How it works`,\n",
        "  - convert the prompt into a format the robot understands.\n",
        "  - Generate a reponse from the robot.\n",
        "  - Convert the reponse back into readable text.\n",
        "5. Putting it all together.\n",
        "- `extract_information_from_text`, Uses the prompt template and robot to extract information from the text we got from the PDF.\n",
        "- `How it works`,\n",
        "  - Format the text with the prompt template.\n",
        "  - Generate and return the information using the robot.\n",
        "6. Using Everything\n",
        "- `What it Does`, Reads the PDF, extracts the text, and gets the information we need.\n",
        "- `How it works`,\n",
        "  - Read the pdf file.\n",
        "  - Extract information from the text using robot.\n",
        "  - print the result."
      ],
      "metadata": {
        "id": "-TnpL6yciuiR"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "orcvScMvitaq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}